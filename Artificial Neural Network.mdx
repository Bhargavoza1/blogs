---
title: 'Artificial Neural Network'
image: 'https://raw.githubusercontent.com/Bhargavoza1/blogs/main/images/ann/neuron.png'
description: 'A neural network is like a team of interconnected perceptrons (basic computing units) that imitates, in a simplified way, how the human brain works...'
date: '2023-12-14'
tags: ['deeplearning','neuralnetwork','ann','blog']
---

I have always been intrigued by the workings of the human brain and how it enables us to comprehend various sounds and discern the intricacies of colors. 
With each new piece of knowledge I acquire, I realize that there are numerous concepts at play in our quest for understanding.

The human brain is an incredibly intricate and advanced organ, and its ability to process information and perceive details is a result of complex neural mechanisms. However, what is the fundamental concept that underlies these processes? 
Mathematics and wave functions emerge as key players in explaining and comprehending the mechanisms of perception and information processing within the brain. In this blog, we will solely focus on the role of Mathematics in this regard.

Now, let's delve into a fascinating realm that bridges the sophistication of the human brain with cutting-edge technology—artificial neural networks.


# Neuron
<CustomImage src="https://raw.githubusercontent.com/Bhargavoza1/blogs/main/images/ann/neuron.png"  alt="biological neuron" height={512} width={1000} />

## Biological Neuron
The human brain consists of a complex network of billions of interconnected neurons. Neurons play a crucial role in processing and transmitting chemical and electrical signals. 
Cell nucleus(core) or Soma processes the information received from dendrites. Axon is a cable that is used by neurons to send information. Synapse is the connection between an axon and other neuron dendrites. 
Dendrites, on the other hand, are extensions that receive information from neighboring neurons. 
his brief statement provides us short idea of how our neuron cell behave.

## Artificial Neuron(Perceptron)
Artificial neuron, also referred to as perceptrons, serve as the fundamental building blocks of neural networks. 
These mathematical functions are derived from the structure of biological neurons and can be likened to basic logic gates that produce binary outputs. They are occasionally referred to as perceptrons as well.

# Perceptron
It is the primary step to learn Machine Learning and Deep Learning technologies, which consists of a set of weights, input values or scores, and a bias. 
Perceptron is a building block of an Artificial Neural Network. Initially, in the mid of 19th century, Mr. Frank Rosenblatt invented the Perceptron for performing certain calculations to detect input data capabilities or business intelligence. 
Perceptron is a linear Machine Learning algorithm used for supervised learning for various binary classifiers. This algorithm enables neurons to learn elements and processes them one by one during preparation. 
<CustomImage src="https://raw.githubusercontent.com/Bhargavoza1/blogs/main/images/ann/perceptron.png"  alt="perceptron" height={512} width={512} />
```math
y = 
\begin{cases} 
1, & \text{if} \quad \sum^n_{i=1} w_i x_i \geq \theta \\ 
0, & \text{otherwise} 
\end{cases}
```

Please be patient as I provide a detailed explanation of neural networks. We will thoroughly dissect each component of the neural network, and I will also provide a Python code snippet for the mathematical equations involved.
Let’s begin 


## Input Layer(X)
The Perceptron's main element is responsible for receiving the initial data and facilitating its subsequent processing within the system. Each input node is designed to hold a specific real numerical value.

## Wight(w) and Bias(b)
The weight parameter signifies the magnitude of the link between units. It is a crucial parameter within the Perceptron components. The weight is directly correlated to the influence of the corresponding input neuron in determining the output. 
Additionally, the bias can be viewed as the intercept line in a linear equation.

## Activation Function
The neuron's firing potential is influenced by these crucial and definitive elements. The Activation Function, in particular, can be predominantly viewed as a step function.
 [Multiple Activation functions](https://en.wikipedia.org/wiki/Activation_function)

```math
Y =\bigg(\sum_{i=1}^n W_iX_i + b)
```

# Neural Network
A neural network is like a team of interconnected perceptrons (basic computing units) that imitates, in a simplified way, how the human brain works. 
Each perceptron is connected to others, and during learning, these connections get adjusted. While it's inspired by the brain,It's a simpler model created for specific tasks, not as complex as the real thing.